[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/YM0Aj0xh)
# README
## Project Milestone 3 Description
- Don't forget to read [the project description](https://docs.google.com/document/d/1SY1HAfrpoj9B6FnO3LEChne4vdf1GOuswu-H7oUUt8A/edit) before starting milestone 3.
- All references for the project, such as submission examples or tutorials will be in [this project reference folder](https://drive.google.com/drive/folders/1rc2w25A5_HfI3ieHxs4ya9UaiUO41dXz?usp=sharing).
- For a detailed documentation on how to use our GPT Wrapper package, please read [this document](https://docs.google.com/document/d/1ZifVg2lw0EzeiuyT20DvZz90GBi3RsoL5tOw22a7BK0/edit?usp=sharing) that is also in the reference folder.
- For a detailed documentation on how to use our GCP , please read [this document](https://docs.google.com/presentation/d/1GJqog51fZ4Yqkw6y0HsS1u28ggPaSWMMgKOAqi7gY1c/edit#slide=id.p) that is also in the reference folder.
    
## Deliverables

The third milestone deliverables require you to commit the following files in your github classroom repository:

- ✅ A JSON file called `answers_<team-name>.json` consisting the answers generated by your generative model for the testing questions in `prompts.json`. We provide you a sample JSON of the testing questions in `prompts.json`. The answer JSON file should be a list of dictionaries with 2 keys “guid” and “model_answer”. The “guid” is to specify the question id and the “model_answer” key should be your model’s generations. The “answer” key in the prompts.json file is just to guide you what the solution of the question is. However, your model’s answer does not have to match this. You are welcome to prompt the model for these questions as you want. Make sure the script below handles this so we get the exact same answer.

- ✅ A python script called `gen_script_<team-name>.json` that allows anyone to easily access your generative model to produce answers for the testing questions. The answers from this script should match exactly to your submitted answers. It’s very important for this script to be reproducible so we can grade you, therefore please also prepare a `requirements.txt` file specifying the package versions, and a `python.txt` file to specify the python version. Make sure that your script is reproducible by testing from an environment from scratch.

- ✅ The final generative model you have trained and used to generate the answers for the testing questions. The details are in the [project description](https://docs.google.com/document/d/1SY1HAfrpoj9B6FnO3LEChne4vdf1GOuswu-H7oUUt8A/edit). You should have the freedom to construct, train, and save your model however you want to (also with the freedom to use any training data and learning algorithms you want to). However, you need to ensure that we can easily use this model through the python script described above to generate answers. Your generation model does not have to handle multi-interaction prompts, although if you would like to implement such a model you are welcome to. You will only be evaluated on one turn prompts. There won’t be a metric-based evaluation, we will only qualitatively look at your generations.

- ✅ Training datasets you've constructed for both the **reward model** and the **generative model**, as detailed in the [project description](https://docs.google.com/document/d/1SY1HAfrpoj9B6FnO3LEChne4vdf1GOuswu-H7oUUt8A/edit). Please name them `reward_dataset_<team-name>.<any-format>` and` gen_dataset_<team-name>.<any-format>` We are **flexible** about the format you submit these datasets in.

- ✅ The reward model you used to train your generative model, as detailed in the [project description](https://docs.google.com/document/d/1SY1HAfrpoj9B6FnO3LEChne4vdf1GOuswu-H7oUUt8A/edit). This model can be a new reward model that is different from what you trained in Milestone 2. However, the format of this model must not change from Milestone 2. In other words, this reward model needs to be **compatible** with the Milestone 2 **evaluation script** as detailed in our previous annoucement.

- ✅ The final report PDF as detailed in the [Final Report Specification](https://docs.google.com/document/d/1ckH2Uy_NrZD8CO6q3PmqviS60AY2rvKJGrNPrlPxTe4/edit?usp=sharing). Please call it `final_report_<team-name>.pdf`.
